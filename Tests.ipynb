{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-g3w2iaek because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from os import path, listdir\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Conv2DTranspose, Dense, MaxPool2D, LeakyReLU, \\\n",
    "BatchNormalization, Dropout, Reshape, Flatten, RepeatVector, Add, ReLU, GlobalAveragePooling2D, AveragePooling2D, \\\n",
    "UpSampling2D, Layer\n",
    "from tensorflow.keras import Model, Input, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.constraints import  max_norm\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = 'train_resized'\n",
    "PROGRESS_FOLDER = 'progress'\n",
    "TARGET_SHAPE = (28, 28, 3)\n",
    "RANDOM_FEATURES_SIZE = 98\n",
    "FILTERS = 128\n",
    "SIZE = 4\n",
    "EPOCHS = 130\n",
    "BATCH_SIZE = 256\n",
    "STEPS_PER_EPOCH = 500\n",
    "SHOW_EVERY = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(map(lambda x: path.join(FOLDER, x), listdir(FOLDER)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNorm(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PixelNorm, self).__init__(**kwargs)\n",
    "        \n",
    "        \n",
    "    def call(self, data):\n",
    "        squared = data**2\n",
    "        mean = backend.mean(squared, axis=-1, keepdims=True)\n",
    "        norm = backend.sqrt(mean + 1.0e-8)\n",
    "        return data / norm\n",
    "    \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSum(Add):\n",
    "    def __init__(self, alpha=0.0, **kwargs):\n",
    "        super(WeightedSum, self).__init__(**kwargs)\n",
    "        self.alpha = backend.variable(alpha, name='WS_alpha')\n",
    "        \n",
    "    \n",
    "    def _blend(self, data):\n",
    "        assert (len(data) == 2)\n",
    "        blended = (1.0 - self.alpha) * data[0] + self.alpha * data[1]\n",
    "        return blended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "### GENERATOR\n",
    "# (SHAPE - KERNEL + 2PADDING) / STRIDE + 1\n",
    "# (SHAPE - 1) * STRIDE + KERNEL - 2PADDING\n",
    "\n",
    "generator_input = Input(RANDOM_FEATURES_SIZE)\n",
    "\n",
    "dropout = 0.4\n",
    "depth = 64+64+64+64\n",
    "dim = 7\n",
    "# In: 100\n",
    "# Out: dim x dim x depth\n",
    "X = Dense(dim*dim*depth)(generator_input)\n",
    "X = BatchNormalization(momentum=0.9)(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Reshape((dim, dim, depth))(X)\n",
    "X = Dropout(dropout)(X)\n",
    "\n",
    "X = UpSampling2D()(X)\n",
    "X = Conv2DTranspose(int(depth/2), 5, padding='same')(X)\n",
    "X = BatchNormalization(momentum=0.9)(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X = UpSampling2D()(X)\n",
    "X = Conv2DTranspose(int(depth/4), 5, padding='same')(X)\n",
    "X = BatchNormalization(momentum=0.9)(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X = Conv2DTranspose(int(depth/8), 5, padding='same')(X)\n",
    "X = BatchNormalization(momentum=0.9)(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X = Conv2DTranspose(3, 5, padding='same')(X)\n",
    "X = Activation('tanh')(X)\n",
    "\n",
    "print(X.shape)\n",
    "assert X.shape[1] == TARGET_SHAPE[0]\n",
    "\n",
    "generator = Model(generator_input, X)\n",
    "#generator.summary()\n",
    "#generator.compile(opt, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "### DISCRIMINATOR\n",
    "\n",
    "discriminator_input = Input(TARGET_SHAPE)\n",
    "\n",
    "depth = 64\n",
    "dropout = 0.4\n",
    "\n",
    "X = Conv2D(depth*1, 5, strides=2, padding='same')(discriminator_input)\n",
    "X = LeakyReLU(alpha=0.2)(X)\n",
    "X = Dropout(dropout)(X)\n",
    "\n",
    "X = Conv2D(depth*2, 5, strides=2, padding='same')(X)\n",
    "X = LeakyReLU(alpha=0.2)(X)\n",
    "X = Dropout(dropout)(X)\n",
    "\n",
    "X = Conv2D(depth*4, 5, strides=2, padding='same')(X)\n",
    "X = LeakyReLU(alpha=0.2)(X)\n",
    "X = Dropout(dropout)(X)\n",
    "\n",
    "X = Conv2D(depth*8, 5, strides=1, padding='same')(X)\n",
    "X = LeakyReLU(alpha=0.2)(X)\n",
    "X = Dropout(dropout)(X)\n",
    "\n",
    "X = Flatten()(X)\n",
    "X = Dense(1)(X)\n",
    "X = Activation('sigmoid')(X)\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "discriminator = Model(discriminator_input, X)\n",
    "\"\"\"\n",
    "### LETS TRY EFFICIENT NET B0 WITH RANDOM WEIGHTS\n",
    "\n",
    "discriminator = Sequential()\n",
    "\n",
    "discriminator.add(EfficientNetB0(include_top=False, input_tensor=discriminator_input, pooling='avg'))\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\"\"\"\n",
    "#discriminator.summary()\n",
    "discriminator.compile(opt, 'binary_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = Input(RANDOM_FEATURES_SIZE)\n",
    "\n",
    "generated_img = generator(gan_input)\n",
    "\n",
    "gan_out = discriminator(generated_img)\n",
    "\n",
    "gan = Model(gan_input, gan_out)\n",
    "#gan.summary()\n",
    "gan.compile(opt, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(count):\n",
    "    images = list()\n",
    "    for choiced in np.random.choice(train, size=count, replace=False):\n",
    "        images.append(np.load(choiced))\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:58<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; Discriminator loss: 0.7051420211791992; GAN loss: 2.9062678813934326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:50<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1; Discriminator loss: 0.08527487516403198; GAN loss: 0.19073942303657532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:49<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2; Discriminator loss: 0.24089208245277405; GAN loss: 0.5318255424499512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:48<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3; Discriminator loss: 0.47159886360168457; GAN loss: 0.5887347459793091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:56<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4; Discriminator loss: 0.44175827503204346; GAN loss: 0.8627838492393494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:07<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5; Discriminator loss: 0.42020270228385925; GAN loss: 1.6112477779388428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:03<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6; Discriminator loss: 0.48684796690940857; GAN loss: 1.1800661087036133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:52<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7; Discriminator loss: 0.3895328938961029; GAN loss: 0.6036587357521057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 227/500 [02:09<02:35,  1.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-645c033eda7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRANDOM_FEATURES_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mfake_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrue_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9726cd966bcd>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(count)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchoiced\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoiced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 440\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \"\"\"\n\u001b[0;32m--> 715\u001b[0;31m     \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m     \u001b[0m_check_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfortran_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_array_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_magic\u001b[0;34m(fp)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMAGIC_PREFIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_str\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_str\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_has_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### TRAIN?\n",
    "\n",
    "demo_noise = np.random.normal(0, 1, (9, RANDOM_FEATURES_SIZE))\n",
    "\n",
    "d_y = np.zeros((2*BATCH_SIZE, 1))\n",
    "d_y[:BATCH_SIZE, :] = 1\n",
    "g_y = np.ones((BATCH_SIZE, 1))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for step in tqdm(range(STEPS_PER_EPOCH)):\n",
    "        noise = np.random.normal(0, 1, (BATCH_SIZE, RANDOM_FEATURES_SIZE))\n",
    "        fake_imgs = generator.predict(noise)\n",
    "        true_imgs = load_images(BATCH_SIZE)\n",
    "        \n",
    "        x = np.concatenate((true_imgs, fake_imgs))\n",
    "        \n",
    "        d_loss = discriminator.train_on_batch(x, d_y)\n",
    "        \n",
    "        noise = np.random.normal(0, 1, (BATCH_SIZE, RANDOM_FEATURES_SIZE))\n",
    "        g_loss = gan.train_on_batch(noise, g_y)\n",
    "    print(f'Epoch: {epoch}; Discriminator loss: {d_loss[0]}; GAN loss: {g_loss}')#'; D_acc: {d_loss[1]}')\n",
    "    if SHOW_EVERY:\n",
    "        if not epoch % SHOW_EVERY:\n",
    "            plt.figure(figsize=(16, 16))\n",
    "            preds = generator.predict(demo_noise)\n",
    "            preds = (preds - preds.min()) / (preds.max() - preds.min())\n",
    "            for i, pred in enumerate(preds):\n",
    "                plt.subplot(3, 3, i+1)\n",
    "                plt.imshow(pred*0.5+0.5, 'gray')\n",
    "                plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(path.join(PROGRESS_FOLDER, f'EPOCH_{epoch}.png'))\n",
    "            #plt.show()\n",
    "            plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
